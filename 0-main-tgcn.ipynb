{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d657339",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "data = pd.read_csv(\"C:\\\\UnderGrad\\\\data\\\\ChargePoint_Data_CY20Q4.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e42c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Energy (kWh)':'Energy'}, inplace=True)\n",
    "data['Start Date'] = pd.to_datetime(data['Start Date'])\n",
    "#Flooring the date to a daily format\n",
    "data['Start Date'] = data['Start Date'].dt.floor('D')\n",
    "data.set_index('Start Date', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd434899",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc['2012-01-01':]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c908a",
   "metadata": {},
   "source": [
    "### T-GCN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec31d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin,cos,sqrt,atan2,radians\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "def distance(x,y):\n",
    "    '''\n",
    "        Calculates the distance between two points x & y.\n",
    "        Returns the distance in meters.\n",
    "    '''\n",
    "    R=6373.0 \n",
    "    lat_1 = radians(abs(x['Latitude']))\n",
    "    lon_1 = radians(abs(x['Longitude']))\n",
    "    lat_2 = radians(abs(y['Latitude']))\n",
    "    lon_2 = radians(abs(y['Longitude']))\n",
    "    \n",
    "    lon_dist = lon_2 - lon_1\n",
    "    lat_dist = lat_2 - lat_1\n",
    "    \n",
    "    #Haversine formula\n",
    "    z = sin(lat_dist/2)**2 + (cos(lat_1) * cos(lat_2) * sin(lon_dist/2)**2)\n",
    "    c = atan2(sqrt(z), sqrt(1-z)) * 2\n",
    "    \n",
    "    #distance in km\n",
    "    dist = R*c\n",
    "    return dist\n",
    "\n",
    "def adj_norm(adj):\n",
    "    '''\n",
    "        Returns sparse normalized adjacency matrix\n",
    "    '''\n",
    "    d = sp.diags(np.power(np.array(adj.sum(1)), -0.5).flatten(), 0)\n",
    "    adjnorm = d.dot(adj).transpose().dot(d).tocsr()\n",
    "\n",
    "    return adjnorm\n",
    "\n",
    "\n",
    "def getGraph(data):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    #Creating a graph for each station\n",
    "    for station in data['Station Name'].unique():\n",
    "        G.add_node(station)\n",
    "        G.nodes[station]['Station Name'] = data[data['Station Name']==station]['Station Name'].iloc[0]\n",
    "        G.nodes[station]['Latitude'] = data[data['Station Name']==station]['Latitude'].iloc[0]\n",
    "        G.nodes[station]['Longitude'] = data[data['Station Name']==station]['Longitude'].iloc[0]\n",
    "        G.nodes[station]['Position'] = (G.nodes[station]['Longitude'], G.nodes[station]['Latitude'])\n",
    "        \n",
    "    for x in G.nodes:\n",
    "        for y in G.nodes:\n",
    "            dist = distance(G.nodes[x], G.nodes[y])\n",
    "            if (dist>2.5):\n",
    "                continue\n",
    "            G.add_edge(x,y)\n",
    "            G[x][y]['weight'] = np.exp(-dist)\n",
    "    \n",
    "    adj = nx.adjacency_matrix(G)\n",
    "    adjnorm = adj_norm(adj).todense()\n",
    "    return G, adj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef0856",
   "metadata": {},
   "source": [
    "### Train Test split  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def setupTGCN(data,forecast_h):\n",
    "    if forecast_h not in [1,7, 30]:\n",
    "        raise ValueError('Forecasting horizon must be 1, 7 or 30')\n",
    "\n",
    "    numlags=30\n",
    "    #getting graph and adj matrix\n",
    "    G, adj = getGraph(data)\n",
    "    #calculating number of days in the data\n",
    "    num_h = int(((data.index.max()-data.index.min()).total_seconds()))\n",
    "    num_h = int(num_h//(3600*24))\n",
    "    #initializing timeseries array\n",
    "    ts = np.zeros([len(G.nodes()), num_h+1])\n",
    "    starttime = data.index.min()\n",
    "\n",
    "    #looping through each day\n",
    "    for i in range(num_h+1):\n",
    "        window = starttime + timedelta(days=i)\n",
    "        current = data[(data.index == window)]\n",
    "\n",
    "        #populating the array for each graph node\n",
    "        for j, n in enumerate(G.nodes()):\n",
    "            temp = current[G.nodes[n]['Station Name']==current['Station Name']]\n",
    "            ts[j,i] = np.sum(temp['Energy'])\n",
    "\n",
    "    #replacing values equal to zero with random numbers\n",
    "    ts[ts==0] = np.random.normal(np.zeros_like(ts[ts==0]), 5)\n",
    "\n",
    "    #normalizing data\n",
    "    max_ = np.max(ts, axis=1)[:,None]\n",
    "    norm = ts/max_\n",
    "\n",
    "    #initializing lagged matrix\n",
    "    num_nodes = len(G.nodes())\n",
    "    matrixlags = np.zeros((ts.shape[-1]-(numlags+forecast_h), ts.shape[0], numlags+forecast_h))\n",
    "    rng=matrixlags.shape[0]\n",
    "    if forecast_h in [1,7]:\n",
    "        itrain = rng - 30\n",
    "    else:\n",
    "        itrain = rng - 120\n",
    "    itest=rng\n",
    "    for i in range(rng):\n",
    "        matrixlags[i] = norm[:,i:i+numlags+forecast_h]\n",
    "\n",
    "    #-------------Train/Test split--------------------------\n",
    "    X_train = np.zeros((itrain,num_nodes, numlags))\n",
    "    y_train = np.zeros((itrain,num_nodes, forecast_h))\n",
    "    X_test = np.zeros((itest-itrain,num_nodes, numlags))\n",
    "    y_test = np.zeros((itest-itrain,num_nodes, forecast_h))\n",
    "\n",
    "    for i, n in enumerate(G.nodes):\n",
    "        X_train[:,i,:] = matrixlags[:itrain,i,:numlags]\n",
    "        y_train[:,i,:] = matrixlags[:itrain,i,numlags:]\n",
    "        X_test[:,i,:] = matrixlags[itrain:itest,i,:numlags]\n",
    "        y_test[:,i,:] = matrixlags[itrain:itest,i,numlags:]\n",
    "\n",
    "    #denormalizing\n",
    "    X_test_denorm = X_test * max_\n",
    "    y_test_denorm = y_test * max_\n",
    "\n",
    "    print(f'X_train shape: {X_train.shape}')\n",
    "    print(f'y_train shape: {y_train.shape}')\n",
    "    print(f'X_test shape: {X_test.shape}')\n",
    "    print(f'y_test shape: {y_test_denorm.shape}')\n",
    "    return G, adj, X_train, y_train, X_test, y_test_denorm, max_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934cbf5",
   "metadata": {},
   "source": [
    "### TGCN Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129495e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models,Input, optimizers, regularizers\n",
    "from tensorflow.keras.layers import Layer,Input, Reshape, Permute, LSTM, BatchNormalization, Dense, Lambda\n",
    "\n",
    "class GraphConvLayer(layers.Layer):\n",
    "    def __init__(self, filters, adj, reg_lambda):\n",
    "        super(GraphConvLayer, self).__init__()\n",
    "        self.filters=filters\n",
    "        self.adj=tf.cast(adj.toarray(), tf.float32) #ensuring adjacency matrix is float32\n",
    "        self.reg_lambda = reg_lambda\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(shape=(input_shape[-1], self.filters),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     regularizer=regularizers.l2(self.reg_lambda),\n",
    "                                     trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        #adding self loop to adj matrix (A+I)\n",
    "        adj_selfloop = self.adj + tf.eye(tf.shape(self.adj)[0], dtype=tf.float32)\n",
    "        #computing degree matrix D_e\n",
    "        degree_matrix = tf.reduce_sum(adj_selfloop, axis=-1)\n",
    "        #computing D_e^{-1/2}\n",
    "        degree_matrix_sqrt = tf.linalg.diag(tf.pow(degree_matrix, -0.5))\n",
    "        #computing normalized adjacency matrix Ab = D_e^{-1/2}*(A+I)*D_e^{-1/2}\n",
    "        adjnorm = tf.matmul(tf.matmul(degree_matrix_sqrt, adj_selfloop), degree_matrix_sqrt)\n",
    "        #Graph Conv Ab*X*W\n",
    "        x = tf.matmul(adjnorm, inputs) #Ab*X\n",
    "        x = tf.matmul(x, self.kernel) #Ab*X*W\n",
    "        x = tf.nn.relu(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTGCN(input_shape, adj, forecast_h):\n",
    "    reg_lambda = 0.02\n",
    "    nodes = input_shape[0]\n",
    "    inputs = Input(shape=input_shape)\n",
    "    #1st Graph Conv layer | 16 filters\n",
    "    x = GraphConvLayer(16,adj, reg_lambda=reg_lambda)(inputs)\n",
    "    #2nd Graph Conv layer | 10 filters\n",
    "    x = GraphConvLayer(10,adj, reg_lambda=reg_lambda)(x)\n",
    "    #LSTM layer\n",
    "    x = layers.LSTM(50, return_sequences=False, kernel_regularizer=regularizers.l2(reg_lambda))(x)\n",
    "    #dense layer with forecast horizon for each station\n",
    "    x = layers.Dense(forecast_h*nodes, kernel_regularizer=regularizers.l2(reg_lambda))(x)\n",
    "    #reshaping to (batch_size, stations, forecast_h)\n",
    "    out = layers.Reshape((nodes, forecast_h))(x)\n",
    "    \n",
    "    mdl = models.Model(inputs=inputs, outputs=out)\n",
    "    mdl.compile(optimizer=optimizers.Adam(), loss='mae')\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3829ae",
   "metadata": {},
   "source": [
    "### One Day Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ef7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_h=1\n",
    "G, adj, X_train1, y_train1, X_test1, y_test1, max_ = setupTGCN(data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a5370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train1.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30577e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl1 = buildTGCN(input_shape, adj, 1)\n",
    "mdl1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaa50f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdl1.fit(X_train1,y_train1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=mdl1.predict(X_test1)\n",
    "pred1 = pred1 * max_\n",
    "totalpred1 = np.sum(pred1, axis=(1))\n",
    "totalactual1 = np.sum(y_test1, axis=(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b02f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse1 = np.sqrt(np.mean((totalpred1-totalactual1)**2))\n",
    "print(f'RMSE for T-GCN in 1 forecasting days: {rmse1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38830d08",
   "metadata": {},
   "source": [
    "### Seven Day Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e788452",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forecast_h=7\n",
    "G, adj, X_train7, y_train7, X_test7, y_test7, max_ = setupTGCN(data, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdd1ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = X_train7.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d170a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mdl7 = buildTGCN(input_shape, adj, 7)\n",
    "mdl7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cfc07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdl7.fit(X_train7, y_train7, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ffe3a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred7=mdl7.predict(X_test7)\n",
    "pred7 = pred7 * max_\n",
    "totalpred7 = np.sum(pred7, axis=(1))\n",
    "totalactual7 = np.sum(y_test7, axis=(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse7 = np.sqrt(np.mean((totalpred7-totalactual7)**2))\n",
    "print(f'RMSE for T-GCN in 7 forecasting days: {rmse7}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9151dd4a",
   "metadata": {},
   "source": [
    "### 30 Day Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9cca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_h=30\n",
    "G, adj, X_train30, y_train30, X_test30, y_test30, max_ = setupTGCN(data, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649ebe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_shape = X_train30.shape[1:]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f53fe2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mdl30 = buildTGCN(input_shape, adj, 30)\n",
    "mdl30.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61799342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdl30.fit(X_train30,y_train30, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ec1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred30=mdl30.predict(X_test30)\n",
    "pred30=pred30 * max_\n",
    "totalpred30 = np.sum(pred30, axis=1)\n",
    "totalactual30 = np.sum(y_test30, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f509db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse30 = np.sqrt(np.mean((totalpred30-totalactual30)**2))\n",
    "print(f'RMSE for T-GCN in 30 forecasting days: {rmse30}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68b31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
